{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Is_To_Run_On_Cloud = True\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import json\n",
    "# Is_HPC = True\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# if(Is_HPC):\n",
    "#     pass\n",
    "# else:\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers.core import Flatten, Dense,Dropout\n",
    "from keras import Model\n",
    "from keras.preprocessing.image import  ImageDataGenerator\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import time\n",
    "from time import sleep\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.python.client import device_lib\n",
    "# if(Is_To_Run_On_Cloud):\n",
    "#     from keras import keras_applications as K_Models\n",
    "# else:\n",
    "from keras import applications as K_Models\n",
    "# Is_Running_On_Local_Desktop = True\n",
    "# FAA_HPC = False\n",
    "from classification_models.resnet import ResNet18, ResNet34, preprocess_input\n",
    "\n",
    "    \n",
    "# if(Training_Gauges[\"True Airspeed(kn)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = \"SAME\" # \"VALID\"\n",
    "def LenNet(input_size, output_classes):\n",
    "    # Vanilla CNN. Play around with architecture.\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                     kernel_size = 9, \n",
    "                     strides = 1, \n",
    "                     activation = 'relu', \n",
    "                     padding=PADDING,\n",
    "                     input_shape = (input_size[0],input_size[1],input_size[2])))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                     kernel_size = 7, \n",
    "                     strides = 1, \n",
    "                     activation = 'relu',\n",
    "                     padding=PADDING,\n",
    "                    ))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                     kernel_size = 5, \n",
    "                     strides = 1, \n",
    "                     activation = 'relu', \n",
    "                     padding=PADDING,\n",
    "                     ))\n",
    "    model.add(MaxPooling2D(pool_size = 5, strides = 1))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                 kernel_size = 3,\n",
    "                 strides = 1,\n",
    "                 activation = 'relu',\n",
    "                 padding=PADDING,\n",
    "                ))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                 kernel_size = 3,\n",
    "                 strides = 1,\n",
    "                 padding=PADDING,\n",
    "                 activation = 'relu'\n",
    "                 ))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                 kernel_size = 3,\n",
    "                 strides = 1,\n",
    "                 padding=PADDING,\n",
    "                 activation = 'relu'\n",
    "                 ))\n",
    "    model.add(MaxPooling2D(pool_size = 5, strides = 1))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     activation = 'relu',\n",
    "                     padding=PADDING\n",
    "                     ))\n",
    "    model.add(Conv2D(filters = 64, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     activation = 'relu',\n",
    "                     padding=PADDING\n",
    "                    ))\n",
    "    model.add(MaxPooling2D(pool_size = 3, strides = 2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_classes, activation='softmax', name='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################################## \n",
    "def Load_Model():\n",
    "    global ML_Model\n",
    "    if(SELECTED_MODEL == Available_Models.VGG16):\n",
    "        ML_Model = K_Models.VGG16(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.VGG19):\n",
    "        ML_Model = K_Models.VGG19(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.InceptionV3):\n",
    "        ML_Model = K_Models.InceptionV3(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.ResNet50):\n",
    "\n",
    "        ML_Model = K_Models.ResNet50(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "        \n",
    "    elif(SELECTED_MODEL == Available_Models.ResNet18):\n",
    "        ML_Model = ResNet18(input_shape=INPUT_SIZE, weights=INITIALIZATION_WIEGHTS, include_top=INCLUDE_TOP)\n",
    "        \n",
    "    elif(SELECTED_MODEL == Available_Models.ResNet34):\n",
    "        ML_Model = ResNet34(input_shape=INPUT_SIZE, weights=INITIALIZATION_WIEGHTS, include_top=INCLUDE_TOP)\n",
    "        \n",
    "    elif(SELECTED_MODEL == Available_Models.DenseNet121):\n",
    "        ML_Model = K_Models.DenseNet121(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.DenseNet169):\n",
    "        ML_Model = K_Models.DenseNet169(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.DenseNet201):\n",
    "        ML_Model = K_Models.DenseNet201(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.MobileNet):\n",
    "        ML_Model = K_Models.MobileNet(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "\n",
    "    elif(SELECTED_MODEL == Available_Models.InceptionResNetV2):\n",
    "        ML_Model = K_Models.InceptionResNetV2(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.NASNetLarge):\n",
    "        ML_Model = K_Models.NASNetLarge(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                            pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.Xception):\n",
    "        ML_Model = K_Models.Xception(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.NASNetMobile):\n",
    "        ML_Model = K_Models.NASNetMobile(include_top=INCLUDE_TOP, weights=INITIALIZATION_WIEGHTS, \n",
    "                                                              input_tensor=INPUT_TENSOR, input_shape=INPUT_SIZE,\n",
    "                                                              pooling=POOLING, classes=OUTPUT_CLASSES)\n",
    "    elif(SELECTED_MODEL == Available_Models.Lenet_Style):\n",
    "        ML_Model = LenNet(input_size= INPUT_SIZE, output_classes=OUTPUT_CLASSES)\n",
    "        return\n",
    "    else:\n",
    "        print(\"NO MODEL IDENTIFIER MATCHED\")\n",
    "        \n",
    "   \n",
    "    if(POOLING is None):\n",
    "        last_layer = Flatten()(ML_Model.output)\n",
    "    else:\n",
    "        last_layer = ML_Model.output\n",
    "        if(SELECTED_MODEL ==  Available_Models.ResNet18 or SELECTED_MODEL == Available_Models.ResNet34):\n",
    "            last_layer = keras.layers.GlobalAveragePooling2D()(ML_Model.output)\n",
    "        \n",
    "    if(len(Dense_Layers_Neurons) > 0):\n",
    "        for n in Dense_Layers_Neurons:\n",
    "            last_layer = Dense(n, activation='relu')(last_layer)\n",
    "            if(Is_To_Add_Dropout):\n",
    "                last_layer =  Dropout(Dropout_Rate)\n",
    "    else:\n",
    "        if(Is_To_Add_Dropout):\n",
    "    #         for neurons in Dense_Layers:\n",
    "    #             last_layer = Dense(neurons, activation='relu')(last_layer)\n",
    "            last_layer =  Dropout(Dropout_Rate)(last_layer)\n",
    "        \n",
    "    last_layer = Dense(OUTPUT_CLASSES, activation=FINAL_LAYER_CLASSIFICATION_FUCNTION,\n",
    "                       name='softmax')(last_layer)\n",
    "    ML_Model = Model(ML_Model.input, last_layer)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Freeze_Model_Parameters():#ML_Model, FREEZE_EARLY_LAYERS_WIHT_PERCENT):\n",
    "    global ML_Model\n",
    "    if(FREEZE_EARLY_LAYERS_WIHT_PERCENT <= 0):\n",
    "        print(\"Zero layers freezed\")\n",
    "    else:\n",
    "        # Freezing Models Layers\n",
    "        freezed_layers_count = int(len(ML_Model.layers) * FREEZE_EARLY_LAYERS_WIHT_PERCENT)\n",
    "        print(\"Freeze {0} early layers\".format(freezed_layers_count))\n",
    "        for layer in ML_Model.layers[:freezed_layers_count]:\n",
    "            layer.trainable = False\n",
    "    \n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Add_Conv_Regularizer():#ML_Model, FREEZE_EARLY_LAYERS_WIHT_PERCENT):\n",
    "    global ML_Model\n",
    "#     alpha = 0.0001  # weight decay coefficient\n",
    "    if(REGULARIZE_EARLY_LAYERS_WIHT_PERCENT <= 0):\n",
    "        print(\"Zero layers regularized\")\n",
    "    else:\n",
    "        # Freezing Models Layers\n",
    "        regularized_layers_count = int(len(ML_Model.layers) * REGULARIZE_EARLY_LAYERS_WIHT_PERCENT)\n",
    "        print(\"Regularize {0} early layers\".format(regularized_layers_count))\n",
    "        for layer in ML_Model.layers[:regularized_layers_count]:\n",
    "            \n",
    "            if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
    "#                 print(\"Before Regularization Added=\" + str(layer.losses))\n",
    "                layer.add_loss(keras.regularizers.l2(REGULARIZE_EARLY_LAYERS_WITH_RATIO)(layer.kernel))\n",
    "#                 print(\"Layer Name=\", layer.name)\n",
    "#                 print(\"After Regularization Added=\" + str(layer.losses))\n",
    "            if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
    "                layer.add_loss(keras.regularizers.l2(REGULARIZE_EARLY_LAYERS_WITH_RATIO)(layer.bias))\n",
    "            \n",
    "    \n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Compile_Model():#(ML_Model, LEARNING_RATE):\n",
    "    global P_ML_Model\n",
    "    global ML_Model\n",
    "\n",
    "    if(AVAILABLE_GPUs > 1):\n",
    "        print(\"Compiling multi GPU models\")\n",
    "        P_ML_Model = multi_gpu_model(ML_Model, AVAILABLE_GPUs)\n",
    "    else:\n",
    "        print(\"Compiling single GPU model\")\n",
    "        P_ML_Model = ML_Model\n",
    "\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999,\n",
    "            epsilon=None, decay=1e-6, amsgrad=False)\n",
    "    P_ML_Model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Create_Data_Loader():\n",
    "    global TRAIN_GENERATOR\n",
    "    global VALID_GENERATOR\n",
    "    global STEP_SIZE_TRAIN\n",
    "    global STEP_SIZE_VALID\n",
    "    \n",
    "    if(Is_To_Apply_Data_Augmentation):\n",
    "        #Observation: Data augmentation didn't help with guages.\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "#             rotation_range=40,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=[-0.2, 0.2],\n",
    "#             horizontal_flip=True,\n",
    "#             fill_mode='nearest'\n",
    "        )\n",
    "        validation_datagen = ImageDataGenerator(\n",
    "            rescale=1./255)\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    TRAIN_GENERATOR = train_datagen.flow_from_directory(TRAINING_DIRECTORY_PATH,  # this is the target directory\n",
    "                classes =CLASS_MAPPINGS,\n",
    "                target_size=(INPUT_SIZE[0], INPUT_SIZE[1]),  # all images will be resized \n",
    "                batch_size=BATCH_SIZE,\n",
    "                color_mode=COLOR_MODE,\n",
    "                shuffle=SHUFFLE,\n",
    "                seed=SEED,\n",
    "                class_mode='categorical') \n",
    "    print(\"TRAINING_DIRECTORY_PATH=\",TRAINING_DIRECTORY_PATH)\n",
    "    print(\"TRAIN_GENERATOR.class_indices =\", TRAIN_GENERATOR.class_indices)\n",
    "    \n",
    "    VALID_GENERATOR = validation_datagen.flow_from_directory(\n",
    "                VALIDATION_DIRECTORY_PATH,\n",
    "                classes =CLASS_MAPPINGS,\n",
    "                target_size=(INPUT_SIZE[0], INPUT_SIZE[1]),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                color_mode=COLOR_MODE,\n",
    "                seed=SEED,\n",
    "                class_mode='categorical')\n",
    "    print(\"VALIDATION_DIRECTORY_PATH=\",VALIDATION_DIRECTORY_PATH)\n",
    "    print(\"TRAIN_GENERATOR.class_indices =\", VALID_GENERATOR.class_indices)\n",
    "\n",
    "    STEP_SIZE_TRAIN=TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size\n",
    "    STEP_SIZE_VALID=VALID_GENERATOR.n//VALID_GENERATOR.batch_size\n",
    "    print(\"STEP_SIZE_TRAIN=\",STEP_SIZE_TRAIN)\n",
    "    print(\"STEP_SIZE_VALID=\",STEP_SIZE_VALID)\n",
    "##############################################################################################    \n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Get_Model_Storage_Info():\n",
    "    global Model_Name\n",
    "    global Weights_Path\n",
    "    global History_Path\n",
    "    global Model_Path\n",
    "#     Model_Name = \"{0}_{1}_Degree_{2}_With_D_Aug_{3}\".format(\n",
    "#         MODEL_NAME_PREFIX, SELECTED_MODEL, C_Guage, Is_To_Apply_Data_Augmentation)\n",
    "    Model_Name = \"{0}_{1}\".format(\n",
    "        SELECTED_MODEL, C_Guage)\n",
    "    \n",
    "#     Weights_Path = \"{0}/CheckPoint_{1}_Best_Model_Weights_With_D_Aug_{2}.hdf5\".format(Store_Trained_ML_Model_Info_At, \n",
    "#                                                                        Model_Name, Is_To_Apply_Data_Augmentation)\n",
    "    Weights_Path = \"{0}/CheckPoint_{1}.hdf5\".format(\n",
    "                    Store_Trained_ML_Model_Info_At, Model_Name)\n",
    "    \n",
    "#     History_Path = \"{0}/{1}_history_With_D_Aug_{2}\".format(Store_Trained_ML_Model_Info_At, \n",
    "#                                             Model_Name, Is_To_Apply_Data_Augmentation)\n",
    "    History_Path = \"{0}/{1}_history\".format(Store_Trained_ML_Model_Info_At, \n",
    "                                            Model_Name)\n",
    "#     Model_Path = \"{0}/{1}_model_architecture_With_D_Aug_{2}\".format(Store_Trained_ML_Model_Info_At,\n",
    "#                                                           Model_Name, Is_To_Apply_Data_Augmentation)\n",
    "    Model_Path = \"{0}/{1}\".format(Store_Trained_ML_Model_Info_At,\n",
    "                                                          Model_Name)\n",
    "    print(\"Model_Name=\", Model_Name)\n",
    "    print(\"Weights_Path=\", Weights_Path)\n",
    "    print(\"History_Path=\", History_Path)\n",
    "    print(\"Model_Path=\", Model_Path)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Do_Training():#(ML_Model,P_ML_Model,train_generator,validation_generator,STEP_SIZE_TRAIN, STEP_SIZE_VALID, \n",
    "                #EPOCHs, CLASSES_WEIGTHAGES, weights_path):\n",
    "\n",
    "    global History\n",
    "    #lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    checkpoint = ModelCheckpoint(Weights_Path, monitor=Monitor, verbose=1, save_best_only=True, mode=Mode)\n",
    "    early_stopping = EarlyStopping(monitor=Monitor, min_delta=0, patience=EARLY_STOPPING_PATIENCE, verbose=0, \n",
    "                                       mode=Mode)\n",
    "\n",
    "    #     lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "    print(\"CLASSES_WEIGTHAGES=\", CLASSES_WEIGTHAGES)\n",
    "    callbacks_list = [early_stopping,  checkpoint]#, lr_scheduler]\n",
    "    History = P_ML_Model.fit_generator(\n",
    "            TRAIN_GENERATOR,\n",
    "            steps_per_epoch=STEP_SIZE_TRAIN,#FAA_TRAINING_EXAMPLES // FAA_BATCH_SIZE,\n",
    "            epochs=EPOCHs,\n",
    "            validation_data=VALID_GENERATOR,\n",
    "            validation_steps=STEP_SIZE_VALID, #FAA_VALIDATION_EXAMPLES // FAA_BATCH_SIZE,\n",
    "             callbacks=callbacks_list,\n",
    "            class_weight = CLASSES_WEIGTHAGES)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Save_Model_Info():\n",
    "    with open('{0}.json'.format(History_Path), 'w') as f:\n",
    "        json.dump(History.history, f)\n",
    "#     if(Is_HPC):\n",
    "#         print(\"NO PANDA INSTALLATION\")\n",
    "#     else:\n",
    "    pd.DataFrame(History.history).to_csv(\"{0}.csv\".format(History_Path))\n",
    "    try:\n",
    "        model_yaml = ML_Model.to_yaml()\n",
    "        with open(\"{0}.yaml\".format(Model_Path), \"w\") as yaml_file:\n",
    "            yaml_file.write(model_yaml)\n",
    "    except Exception as eExcep:\n",
    "        print(str(eExcep))\n",
    "    model_json = ML_Model.to_json()\n",
    "    with open(\"{0}.json\".format(Model_Path), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "#     ML_Model.save(Model_Path)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Evaluate_Model():\n",
    "    \n",
    "    global TEST_CSV\n",
    "    try:\n",
    "        TEST_CSV[\"{0}_Prd_{1}_Selected_Model_{2}\".format(C_Guage,Model_Name, SELECTED_MODEL)] = None\n",
    "        try:\n",
    "            for index, row in TEST_CSV.iterrows():\n",
    "#                 try:\n",
    "                if(index != 0 and index % 2500 == 0):\n",
    "                    print(\"Predicted Examples Count={0}\".format(index))\n",
    "#                     break\n",
    "                for test_img_path in TEST_CSV[\"ML_File_Path_For_TrainValTest\"][index].split(\",\"):\n",
    "#                     print(\"test_img_path=\", test_img_path)\n",
    "                    try:\n",
    "                        test_img_path = test_img_path.replace(\"./\", \"{0}/\".format(Dell_Path))\n",
    "    #                     print(\"test_img_path=\", test_img_path)\n",
    "                        test_img = cv2.imread(test_img_path, cv2.IMREAD_COLOR)\n",
    "                        test_img = test_img.astype(\"float32\") / 255\n",
    "                        #                     test_img = np.expand_dims(test_img, -1)\n",
    "                        test_img = cv2.resize(test_img, (INPUT_SIZE[0], \n",
    "                                                           INPUT_SIZE[1]))\n",
    "                        test_img = np.reshape(test_img,(1,test_img.shape[0], \n",
    "                                    test_img.shape[1], test_img.shape[2]))\n",
    "                        prediction = np.argmax(ML_Model.predict(test_img, \n",
    "                                                            batch_size=1))\n",
    "                        TEST_CSV[\"{0}_Prd_{1}_Selected_Model_{2}\".format(C_Guage,Model_Name, SELECTED_MODEL)][index] = prediction\n",
    "                        #                 if(TEST_CSV[\"{0}_Prd_{1}\".format(C_Guage,Model_Name)] = None)\n",
    "                        #                 TEST_CSV[\"{0}_Prd_{1}\".format(C_Guage,Model_Name)][index] = prediction\n",
    "    #                     print(\"Prediction=\" + str(prediction))\n",
    "                    except Exception as eERRoR:\n",
    "                        TEST_CSV[\"{0}_Prd_{1}_Selected_Model_{2}\".format(C_Guage,Model_Name, SELECTED_MODEL)][index] = -1\n",
    "                    break\n",
    "#                 except Exception as eError:\n",
    "#                     TEST_CSV[\"{0}_Prd_{1}\".format(C_Guage, Model_Name)][index] = \"Error\"\n",
    "#                     print(\"Some Error Occurred While Prediction.\" + str(eError))\n",
    "#                     continue\n",
    "        except Exception as eError:\n",
    "            TEST_CSV[\"{0}_Prd_{1}_Selected_Model_{2}\".format(C_Guage,Model_Name, SELECTED_MODEL)][index] = \"Error\"\n",
    "            print(\"Some Error Occurred While Prediction.\" + str(eError))\n",
    "\n",
    "        \n",
    "    except Exception as eError:\n",
    "        print(\"Some Error Occurred While Evaluating the Model.\" + str(eError))\n",
    "    \n",
    "                \n",
    "    \n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "def Initiate_Model_Training():\n",
    "#     print(\"SELECTED MODEL #\" + str(Selected_Model))\n",
    "    global ML_Model\n",
    "    global P_ML_Model\n",
    "    \n",
    "    print(\"SELECTED MODEL #\" + str(SELECTED_MODEL))\n",
    "    if(AVAILABLE_GPUs > 1):\n",
    "        with tf.device('/cpu:0'):\n",
    "            Load_Model()\n",
    "    else:\n",
    "        Load_Model()\n",
    "    Add_Conv_Regularizer()\n",
    "    Freeze_Model_Parameters()#(ML_Model, FREEZE_EARLY_LAYERS_WIHT_PERCENT)\n",
    "    Compile_Model()\n",
    "    Create_Data_Loader()\n",
    "    Get_Model_Storage_Info()\n",
    "    ML_Model.summary()\n",
    "    Do_Training()\n",
    "    Save_Model_Info()\n",
    "#     Evaluate_Model()\n",
    "    #Release Resources\n",
    "    ML_Model = None\n",
    "    P_ML_Model = None\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    sleep(COOL_DOWN)\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVAILABLE_GPUs = len([gpu for gpu in device_lib.list_local_devices() if gpu.device_type==\"GPU\"])\n",
    "# print(AVAILABLE_GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVAILABLE_GPUs= 1\n"
     ]
    }
   ],
   "source": [
    "# Global Configurations\n",
    "# Hyper-parameters Configuration etc\n",
    "\n",
    "##############################################################################################\n",
    "#HORIZON MASK OR NOT MASK SETTING\n",
    "# With_Horizon = None\n",
    "# Horizon = None\n",
    "# # Is_Horizon_Masked = False\n",
    "# Degree_Constraints = [3, 4]#, 5, 6]#, 5, 6]#[3, 4, 5, 6]\n",
    "# C_Degree = None # Current Degree Under Training\n",
    "C_Guage = None\n",
    "# C_With_Horizon = None\n",
    "# if(Is_Horizon_Masked):\n",
    "#     With_Horizon = \"With_Horizon_Masked\" \n",
    "# else:\n",
    "#     With_Horizon = \"Without_Horizon_Masked\" \n",
    "# Horizon = [ \"Without_Horizon_Masked\", \"With_Horizon_Masked\",]\n",
    "# print(\"Horizon=\", Horizon)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# ML MODEL\n",
    "#SINGULARITY (Global Variables)\n",
    "# MODEL PARAMETERS\n",
    "#LOCAL MACHINE IS RUNNING MAX VALIDATION ACCURACCY EXP\n",
    "Monitor = \"val_acc\" # Monitor for maximium val_acc or Minimium val_loss\n",
    "Mode = \"auto\" # max for val_acc and min for val_loss\n",
    "COOL_DOWN = 25\n",
    "ML_Model = None\n",
    "P_ML_Model = None\n",
    "TRAIN_GENERATOR = None\n",
    "VALID_GENERATOR = None\n",
    "STEP_SIZE_TRAIN = None\n",
    "STEP_SIZE_VALID = None\n",
    "Model_Name = None\n",
    "Weights_Path = None\n",
    "History_Path = None\n",
    "Model_Path = None\n",
    "History = None\n",
    "SEED = 101\n",
    "OUTPUT_CLASSES = 9\n",
    "AVAILABLE_GPUs = len([gpu for gpu in device_lib.list_local_devices() if gpu.device_type==\"GPU\"])\n",
    "if(AVAILABLE_GPUs == 0):\n",
    "    AVAILABLE_GPUs = 1\n",
    "    print(\"AVAILABLE_GPUs = 0 (NO GPU ACCESS)\")\n",
    "print(\"AVAILABLE_GPUs=\",AVAILABLE_GPUs)\n",
    "\n",
    "FINE_TUNE = False\n",
    "\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "COLOR_MODE = \"rgb\"\n",
    "FINAL_LAYER_CLASSIFICATION_FUCNTION = \"softmax\"\n",
    "SHUFFLE = True  \n",
    "POOLING = None#\"avg\" # avg or max or None for flatten\n",
    "INITIALIZATION_WIEGHTS = \"imagenet\"\n",
    "INCLUDE_TOP = False\n",
    "FREEZE_EARLY_LAYERS_WIHT_PERCENT = 0\n",
    "INPUT_SIZE = (224,224, 3)\n",
    "INPUT_TENSOR = None\n",
    "BATCH_SIZE = 0 # Must be zero here \n",
    "EPOCHs = 500\n",
    "\n",
    "\n",
    "# 25000 Classes\n",
    "CLASSES_WEIGTHAGES = None\n",
    "#{0: 1.0, 1: 1.9471826700742363, 2: 1.0, \n",
    "                      #3: 1.0, 4: 1.8986590720303786, 5: 1.7509301816590064,\n",
    "                      #6: 7.0609002647837595, 7: 10.256410256410257, 8: 1.0}\n",
    "\n",
    "\n",
    "######################################\n",
    "# Is_To_Apply_Class_Weigtage = False\n",
    "#Degree 3 Constrant On P & R\n",
    "# Classwise_Dist_Degree_3= {0: 16000, 1: 8217, 2: 16000, 3: 16000, 4: 8427, 5: 9138, 6: 2266, 7: 1560, 8: 16000}\n",
    "# Classwise_Weightage_Degree_3= {0: 1.0, 1: 1.9471826700742363, 2: 1.0, 3: 1.0, 4: 1.8986590720303786, 5: 1.7509301816590064, \n",
    "#                                6: 7.0609002647837595, 7: 10.256410256410257, 8: 1.0}\n",
    "\n",
    "######################################\n",
    "######################################\n",
    "# Classwise_Dist_Degree_4= {0: 16000, 1: 3034, 2: 16000, 3: 16000, 4: 4486, 5: 3702, 6: 953, 7: 417, 8: 16000}\n",
    "# Classwise_Weightage_Degree_4= {0: 1.0, 1: 5.273566249176005, 2: 1.0, 3: 1.0, 4: 3.5666518056174765, 5: 4.321988114532685, \n",
    "#                                6: 16.7890870933893, 7: 38.36930455635492, 8: 1.0}\n",
    "######################################\n",
    "######################################\n",
    "# Classwise_Dist_Degree_5= {0: 14316, 1: 1502, 2: 16000, 3: 16000, 4: 2059, 5: 1448, 6: 572, 7: 131, 8: 16000}\n",
    "# Classwise_Weightage_Degree_5= {0: 1.1176306230790725, 1: 10.652463382157125, 2: 1.0, 3: 1.0, 4: 7.770762506070908, 5: 11.049723756906078, \n",
    "#                                6: 27.972027972027973, 7: 122.13740458015268, 8: 1.0}\n",
    "######################################\n",
    "######################################\n",
    "# Classwise_Dist_Degree_6= {0: 9740, 1: 840, 2: 16000, 3: 16000, 4: 959, 5: 531, 6: 292, 7: 70, 8: 16000}\n",
    "# Classwise_Weightage_Degree_6= {0: 1.6427104722792607, 1: 19.047619047619047, 2: 1.0, 3: 1.0, 4: 16.684045881126174, 5: 30.131826741996232, \n",
    "#                                6: 54.794520547945204, 7: 228.57142857142858, 8: 1.0}\n",
    "######################################\n",
    "# ALL_CLASSES_WEIGTHAGES = {\"3\":Classwise_Weightage_Degree_3, \"4\":Classwise_Weightage_Degree_4,\n",
    "#                      \"5\":Classwise_Weightage_Degree_5, \"6\":Classwise_Weightage_Degree_6}\n",
    "# ALL_CLASSES_DIST = {\"3\":Classwise_Dist_Degree_3, \"4\":Classwise_Dist_Degree_4,\n",
    "#                      \"5\":Classwise_Dist_Degree_6, \"6\":Classwise_Dist_Degree_6}\n",
    "######################################\n",
    "# 30000 Classes\n",
    "# CLASSES_WEIGTHAGES = {0: 1.0, 1: 2.3366192040890836, 2: 1.0, 3: 1.0, 4: 2.2783908864364544, \n",
    "#                    5: 2.101116217990808, 6: 8.473080317740513, 7: 12.307692307692308, 8: 1.0}\n",
    "# CLASSES_WEIGTHAGES_Masked = {\"Degree_3_{0}\".format(\"With_Horizon_Masked\"):CLASSES_WEIGTHAGES\n",
    "# }\n",
    "CLASS_MAPPINGS = []\n",
    "# for label in range(0, OUTPUT_CLASSES):\n",
    "#     CLASS_MAPPINGS.append(str(label))\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "#TRAINED MODEL IDENTIFIER & PATHS\n",
    "# MODEL_NAME_PREFIX = None#\"Attitude_Trained_Model_{0}\".format(With_Horizon)\n",
    "# MODEL_NAME_PREFIX = \"Guages_Trained_Model\"\n",
    "BASE = \".\"#\"/scratch/rotorcraftdata/RU_FAA_Rotorcraft_Safety_Workspace/FAA_Attitude_Estimation\"\n",
    "\n",
    "\n",
    "\n",
    "# DATA PATHS\n",
    "ROOT_DS_FOLDER_PATH = None#\"./Data_{0}/Training Data/Frames_WindSheild_Threshold_{1}_With_Hist_False\".format(C_Degree, With_Horizon)#Frames_WindSheild_Threshold_3_With_Hist_False/\"\n",
    "# ROOT_DS_FOLDER_PATH = \"/home/hikmat/Desktop/DLWSpace/FAA/Data_Without_Horizon_Masked/Frames_WindSheild_Threshold_{0}_With_Hist_False/\".format(\n",
    "#     C_Degree)#/Frames_WindSheild_Threshold_3_With_Hist_False\"\n",
    "TRAINING_DIRECTORY_PATH = None\n",
    "VALIDATION_DIRECTORY_PATH = None\n",
    "TESTING_DIRECTORY_PATH = None\n",
    "Store_Trained_ML_Model_Info_At = None\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# MODEL SELECTION HELP OR AVAILABLE MODELS\n",
    "class Available_Models(Enum):\n",
    "    VGG16 = \"VGG16\"\n",
    "    VGG19 = \"VGG19\"\n",
    "    InceptionV3 = \"InceptionV3\"\n",
    "    Xception = \"Xception\" # TensorFlow ONLY\n",
    "    ResNet50 = \"ResNet50\"\n",
    "    ResNet18 = \"ResNet18\"\n",
    "    ResNet34 = \"ResNet34\"\n",
    "    DenseNet121 = \"DenseNet121\"\n",
    "    DenseNet169 = \"DenseNet169\"\n",
    "    DenseNet201 = \"DenseNet201\"\n",
    "    MobileNet = \"MobileNet\"\n",
    "    InceptionResNetV2 = \"InceptionResNetV2\"\n",
    "    NASNetLarge = \"NASNetLarge\"\n",
    "    NASNetMobile = \"NASNetMobile\"\n",
    "    Lenet_Style = \"Lenet_Style\"\n",
    "##############################################################################################    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gauges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2e934ab93aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mDropout_Rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mIs_To_Apply_Data_Augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_Is_To_Apply_Data_Augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mguage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGauges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mC_Guage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Gauges' is not defined"
     ]
    }
   ],
   "source": [
    "IS_CLASSES_WEIGTHAGES = False\n",
    "Is_To_Add_Dropout = False#True\n",
    "LEARNING_RATE_LST = [0.001]#, 0.0009]#, 0.005, 0.009]\n",
    "Dropout_Rate_LST = [0.25]#, 0.25]#, 0.5, 0.0]\n",
    "Dense_Layers_Neurons = []#[512]\n",
    "LEARNING_RATE = None\n",
    "Dropout_Rate = None\n",
    "TEST_CSV_PATH = None\n",
    "TEST_CSV_Predicted_PATH = None\n",
    "TEST_CSV = None\n",
    "Is_To_Apply_Data_Augmentation = False\n",
    "Is_To_Apply_Data_Augmentation_Lt=[False]#, False]\n",
    "\n",
    "# # Classwise_Dist_Degree_3= {0: 16000, 1: 8217, 2: 16000, 3: 16000, 4: 8427, 5: 9138, 6: 2266, 7: 1560, 8: 16000}\n",
    "# Classwise_Weightage_Degree_3= {0: 1.0, 1: 1.9471826700742363, 2: 1.0, 3: 1.0, 4: 1.8986590720303786, 5: 1.7509301816590064, \n",
    "#                                6: 7.0609002647837595, 7: 10.256410256410257, 8: 1.0}\n",
    "\n",
    "# ######################################\n",
    "# ######################################\n",
    "# # Classwise_Dist_Degree_4= {0: 16000, 1: 3034, 2: 16000, 3: 16000, 4: 4486, 5: 3702, 6: 953, 7: 417, 8: 16000}\n",
    "# Classwise_Weightage_Degree_4= {0: 1.0, 1: 5.273566249176005, 2: 1.0, 3: 1.0, 4: 3.5666518056174765, 5: 4.321988114532685, \n",
    "#                                6: 16.7890870933893, 7: 38.36930455635492, 8: 1.0}\n",
    "# ######################################\n",
    "# ######################################\n",
    "# # Classwise_Dist_Degree_5= {0: 14316, 1: 1502, 2: 16000, 3: 16000, 4: 2059, 5: 1448, 6: 572, 7: 131, 8: 16000}\n",
    "# Classwise_Weightage_Degree_5= {0: 11.1176306230790725, 1: 15.652463382157125, 2: 1.0, 3: 1.0, \n",
    "#                                4: 17.770762506070908, 5: 210.049723756906078, \n",
    "#                                6: 27.972027972027973, 7: 122.13740458015268, 8: 1.0}\n",
    "# ######################################\n",
    "\n",
    "\n",
    "\n",
    "REGULARIZE_EARLY_LAYERS_WIHT_PERCENT = 0\n",
    "REGULARIZE_EARLY_LAYERS_WITH_RATIO = 0.001\n",
    "\n",
    "Dell_Path = \"/home/Eric/FAA_Research/Data/COPILOT_DATA/\" # If training on the local machine\n",
    "# Dell_Path = \".\" # If training on HPC\n",
    "if __name__ == \"__main__\":\n",
    "#     global LEARNING_RATE\n",
    "#     global Dropout_Rate\n",
    "    \n",
    "#     global INPUT_SIZE\n",
    "#     global BATCH_SIZE \n",
    "#     global ROOT_DS_FOLDER_PATH\n",
    "#     global TRAINING_DIRECTORY_PATH\n",
    "#     global VALIDATION_DIRECTORY_PATH\n",
    "# #     global CLASSES_WEIGTHAGES\n",
    "#     global CLASS_MAPPINGS \n",
    "#     global OUTPUT_CLASSES\n",
    "#     global TEST_CSV_PATH\n",
    "# #     global C_Degree\n",
    "# #     global C_With_Horizon\n",
    "# #     global MODEL_NAME_PREFIX\n",
    "#     global Store_Trained_ML_Model_Info_At\n",
    "#     global TEST_CSV\n",
    "#     global TEST_CSV_Predicted_PATH\n",
    "#     global Is_To_Apply_Data_Augmentation\n",
    "\n",
    "\n",
    "\n",
    "#     Dell_Guages = [\"NR(%)\"]\n",
    "#     Rutger_Guages = [\"N1_NG 1(%)\",\"N1_NG 2(%)\",]\n",
    "#     GCP_Guages = [\"Pitch Angle(deg)\"]#\"True Airspeed(kn)\"]#True Airspeed(kn)\"]#\"Pitch Angle(deg)\"]#\"True Airspeed(kn)\"]\n",
    "#     Gauges = GCP_Guages#[\"NR(%)\", \"Torque 1(%)\", \"Torque 2(%)\"]#,\"True Airspeed(kn)\"]#,\"Latitude(deg)\",\"Longitude(deg)\",\"NR(%)\",\"Torque 1(%)\",\n",
    "\n",
    "\n",
    "    for learning_rate, dropout_rate, l_Is_To_Apply_Data_Augmentation in zip(LEARNING_RATE_LST, \n",
    "                                                Dropout_Rate_LST, Is_To_Apply_Data_Augmentation_Lt):\n",
    "        LEARNING_RATE = learning_rate\n",
    "        Dropout_Rate = dropout_rate\n",
    "        Is_To_Apply_Data_Augmentation = l_Is_To_Apply_Data_Augmentation\n",
    "        C_Guage = \"HPE_Models\"\n",
    "#         for guage in Gauges:\n",
    "#             C_Guage = guage\n",
    "\n",
    "#             Trained_Models_Root_Path = \"./Trained_Models_of_Guage_With_Learning_Rate_{0}_With_Dropout_{1}_Ratio_{2}_With_D_Aug_{3}\".format(\n",
    "#             LEARNING_RATE,Is_To_Add_Dropout, Dropout_Rate, Is_To_Apply_Data_Augmentation)\n",
    "        Trained_Models_Root_Path = \"./Trained_Models\"\n",
    "        if(os.path.exists(Trained_Models_Root_Path)):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(Trained_Models_Root_Path)\n",
    "\n",
    "        Store_Trained_ML_Model_Info_At = \"{0}/{1}\".format(Trained_Models_Root_Path, C_Guage)    \n",
    "        if(os.path.exists(Store_Trained_ML_Model_Info_At)):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(Store_Trained_ML_Model_Info_At)\n",
    "\n",
    "        print(\"*\" * 50)\n",
    "        print(\"*\" * 25)\n",
    "        print(\"HPE={0}\".format(C_Guage))\n",
    "#         print(\"C_With_Horizon={0}\".format(C_With_Horizon))\n",
    "#         if(Is_To_Apply_Class_Weigtage is False):\n",
    "#             CLASSES_WEIGTHAGES = None\n",
    "#             print(\"Is_To_Apply_Class_Weigtage={0}\".format(Is_To_Apply_Class_Weigtage))\n",
    "#         else:\n",
    "#             print(\"Is_To_Apply_Class_Weigtage={0}\".format(Is_To_Apply_Class_Weigtage))\n",
    "#             CLASSES_WEIGTHAGES = ALL_CLASSES_WEIGTHAGES[str(C_Degree)]\n",
    "#             continue\n",
    "#         print(\"CLASSES_WEIGTHAGES={0}\".format(CLASSES_WEIGTHAGES))\n",
    "\n",
    "\n",
    "#             ROOT_DS_FOLDER_PATH = \"/home/hikmat/Desktop/DLWSpace/FAA/Data_{0}/Training Data/Frames_WindSheild_Threshold_{1}_With_Hist_False\".format(\n",
    "#                 C_With_Horizon, C_Degree)#Frames_WindSheild_Threshold_3_With_Hist_False/\"\n",
    "#             if(Is_Running_On_Local_Desktop):\n",
    "        if(IS_CLASSES_WEIGTHAGES):\n",
    "            CLASSES_WEIGTHAGES = Classwise_Weightage_Degree_3\n",
    "        else:\n",
    "            CLASSES_WEIGTHAGES = None\n",
    "\n",
    "        ROOT_DS_FOLDER_PATH = \"{1}/Training/Training Data/{0}_Data\".format(\n",
    "        C_Guage, Dell_Path)\n",
    "        TEST_CSV_PATH  = \"{1}/Training/CSV/{0}_ML_CSV_For_CNN_Test.csv\".format(C_Guage, Dell_Path)\n",
    "        TEST_CSV_Predicted_PATH = \"{1}/Training/CSV/{0}_ML_Predicted_CSV_For_CNN_Test_{2}.csv\".format(\n",
    "            C_Guage, Dell_Path, str(datetime.now()))\n",
    "#             elif(FAA_HPC):\n",
    "#                 ROOT_DS_FOLDER_PATH = \"{1}/Training/Training Data/{0}_Data\".format(\n",
    "#                 C_Guage, BASE)\n",
    "#                 #TEST_CSV_PATH  = \"{0}/Training/CSV/{1}_ML_Predicted_CSV_For_CNN_Test.csv\".format(BASE, C_Guage)\n",
    "#                 #TEST_CSV_Predicted_PATH = \"./Training/CSV/{0}_ML_CSV_For_CNN_Test.csv\".format(C_Guage)\n",
    "#             else:\n",
    "#                 ROOT_DS_FOLDER_PATH = \"./Training/Training Data/{0}_Data\".format(\n",
    "#                 C_Guage)\n",
    "#                 #TEST_CSV_PATH  = \"./Training/CSV/{0}_ML_CSV_For_CNN_Test.csv\".format(C_Guage)\n",
    "#                 #TEST_CSV_Predicted_PATH = \"./Training/CSV/{0}_ML_Predicted_CSV_For_CNN_Test.csv\".format(C_Guage)\n",
    "\n",
    "\n",
    "#             True Airspeed(kn)_ML_CSV_For_CNN_Test\n",
    "\n",
    "        TRAINING_DIRECTORY_PATH = \"{0}/TRAINING_DIRECTORY\".format(ROOT_DS_FOLDER_PATH)\n",
    "        OUTPUT_CLASSES = len(os.listdir(TRAINING_DIRECTORY_PATH))\n",
    "        CLASS_MAPPINGS = []\n",
    "        for label in range(0, OUTPUT_CLASSES):\n",
    "#             print(\"Label=\", label)\n",
    "            CLASS_MAPPINGS.append(str(label))\n",
    "        VALIDATION_DIRECTORY_PATH = \"{0}/VALIDATION_DIRECTORY\".format(ROOT_DS_FOLDER_PATH)\n",
    "        TESTING_DIRECTORY_PATH = \"{0}/TESTING_DIRECTORY\".format(ROOT_DS_FOLDER_PATH)\n",
    "\n",
    "        print(\"Current TRAINING_DIRECTORY_PATH={0}\".format(TRAINING_DIRECTORY_PATH))\n",
    "        print(\"Current VALIDATION_DIRECTORY_PATH={0}\".format(VALIDATION_DIRECTORY_PATH))\n",
    "        print(\"Current TESTING_DIRECTORY_PATH={0}\".format(TESTING_DIRECTORY_PATH))\n",
    "        print(\"PREDICTED_CSV_WILL_BE_SAVED_AT_PATH=\" + str(TEST_CSV_Predicted_PATH))\n",
    "        print(\"TEST_CSV_PATH={0}\".format(TEST_CSV_PATH))\n",
    "        #TEST_CSV = pd.read_csv(TEST_CSV_PATH)\n",
    "        print(\"*\" * 25)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             BATCH_SIZE = 96 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (224,224, 3)\n",
    "#             SELECTED_MODEL = Available_Models.ResNet50\n",
    "#             Initiate_Model_Training()\n",
    "\n",
    "\n",
    "#             BATCH_SIZE = 1024 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (64,64, 3)\n",
    "#             SELECTED_MODEL = Available_Models.Lenet_Style\n",
    "#             Initiate_Model_Training()\n",
    "\n",
    "#             BATCH_SIZE = 96 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (224,224, 3)\n",
    "#             SELECTED_MODEL = Available_Models.VGG19\n",
    "#             Initiate_Model_Training()\n",
    "#             print(\"Saving Prediction of {0}\".format(SELECTED_MODEL))\n",
    "#             TEST_CSV.to_csv(TEST_CSV_Predicted_PATH)\n",
    "\n",
    "\n",
    "        BATCH_SIZE = 2048 * AVAILABLE_GPUs\n",
    "        INPUT_SIZE = (64,64, 3)\n",
    "        SELECTED_MODEL = Available_Models.ResNet18\n",
    "        Initiate_Model_Training()\n",
    "        print(\"Saving Prediction of {0}\".format(SELECTED_MODEL))\n",
    "        TEST_CSV.to_csv(TEST_CSV_Predicted_PATH)\n",
    "\n",
    "\n",
    "        #BATCH_SIZE = 512 * AVAILABLE_GPUs\n",
    "        #INPUT_SIZE = (128,128, 3)\n",
    "        #SELECTED_MODEL = Available_Models.ResNet34\n",
    "        #Initiate_Model_Training()\n",
    "        #print(\"Saving Prediction of {0}\".format(SELECTED_MODEL))\n",
    "        #TEST_CSV.to_csv(TEST_CSV_Predicted_PATH)\n",
    "\n",
    "\n",
    "\n",
    "#             BATCH_SIZE = 96 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (224,224, 3)\n",
    "#             SELECTED_MODEL = Available_Models.ResNet50\n",
    "#             Initiate_Model_Training()\n",
    "#             print(\"Saving Prediction of {0}\".format(SELECTED_MODEL))\n",
    "#             TEST_CSV.to_csv(TEST_CSV_Predicted_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             BATCH_SIZE = 32 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (299,299, 3)\n",
    "#             SELECTED_MODEL = Available_Models.Xception\n",
    "#             Initiate_Model_Training()\n",
    "#             print(\"Saving Prediction of {0}\".format(SELECTED_MODEL))\n",
    "\n",
    "\n",
    "#             BATCH_SIZE = 32 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (299,299, 3)\n",
    "#             SELECTED_MODEL = Available_Models.InceptionV3\n",
    "#             Initiate_Model_Training()\n",
    "\n",
    "#             BATCH_SIZE = 32 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (299,299, 3)\n",
    "#             SELECTED_MODEL = Available_Models.InceptionResNetV2\n",
    "#             Initiate_Model_Training()\n",
    "\n",
    "#             BATCH_SIZE = 32 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (224,224, 3)\n",
    "#             SELECTED_MODEL = Available_Models.DenseNet121\n",
    "#             Initiate_Model_Training()\n",
    "\n",
    "#             BATCH_SIZE = 96 * AVAILABLE_GPUs\n",
    "#             INPUT_SIZE = (224,224, 3)\n",
    "#             SELECTED_MODEL = Available_Models.VGG16\n",
    "#             Initiate_Model_Training()\n",
    "\n",
    "#             print(\"SAVING_PREDICTED_CSV_TO_PATH=\" + str(TEST_CSV_Predicted_PATH))\n",
    "        TEST_CSV.to_csv(TEST_CSV_Predicted_PATH)\n",
    "        TEST_CSV = None\n",
    "        TEST_CSV_PATH = None\n",
    "        TEST_CSV_Predicted_PATH = None\n",
    "        print(\"*\" * 25)\n",
    "        print(\"HPE {0} Training Has Completed!\".format(C_Guage))\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEPENDENT EVALUATION ON TESTSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_Guage = \"NR(%)\"\n",
    "# LEARNING_RATE = 0.001\n",
    "# Dropout_Rate = 0.1\n",
    "# Model_Name = \"ResNet50\"\n",
    "# Root_Path = \"/home/hikmat/Desktop/DLWSpace/FAA_Guages_Data/AHS_Github/AHS/Trained_Models_of_Guage_With_Learning_Rate_{0}_With_Dropout_True_Ratio_{1}/{2}\".format(\n",
    "#     LEARNING_RATE, Dropout_Rate, C_Guage)\n",
    "# Model = None\n",
    "# Model_Path =\"{0}/{1}\".format(Root_Path, \"Guages_Trained_Model_Available_Models.{0}_Degree_{1}_model_architecture\".format(Model_Name, C_Guage))\n",
    "\n",
    "# Model_Weights =\"{0}/{1}\".format(Root_Path, \"CheckPoint_Guages_Trained_Model_Available_Models.{0}_Degree_{1}_Best_Model_Weights\".format(Model_Name, C_Guage))\n",
    "\n",
    "# Model = load_model_and_weights_from_path(model_path=Model_Path,\n",
    "#                                          weights_paths=Model_Weights)\n",
    "# TEST_CSV_I = pandas.read_csv(\n",
    "#     \"/home/hikmat/Desktop/DLWSpace/FAA_Guages_Data/Training/CSV/{0}_ML_CSV_For_CNN_Test.csv\".format(C_Guage))\n",
    "# TEST_CSV_I_OutPut_Path = \"/home/hikmat/Desktop/DLWSpace/FAA_Guages_Data/Training/CSV/{0}_{1}_ML_Prd_CSV_For_CNN_Test.csv\".format(C_Guage,Model_Name)\n",
    "# INPUT_SIZE = (224, 224, 3)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_CSV_I = TestSet_Evaluate_Model(TEST_CSV= TEST_CSV_I, \n",
    "#                        Model=Model,Model_Name=Model_Name, C_Guage=C_Guage,\n",
    "#                        INPUT_SIZE=INPUT_SIZE)\n",
    "# TEST_CSV_I.to_csv(TEST_CSV_I_OutPut_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_CSV_I.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
